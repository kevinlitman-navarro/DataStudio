{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import requests\n",
    "from pywaffle import Waffle\n",
    "import numpy as np\n",
    "import squarify\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.pyplot import figure\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'pdf.fonttype': 42,\n",
    "    'axes.prop_cycle': cycler('color', ['#52bbb7', '#8fdeb4', '#f16764', '#ca4862', '#461d2d', '#9C2964', '#1B7EBE', '#E4C34A']),\n",
    "    'ps.fonttype': 42,\n",
    "    'grid.linestyle': '--',\n",
    "    'axes.facecolor': '#8fdeb4',\n",
    "    'figure.facecolor': '#8fdeb4',\n",
    "    'axes.spines.left' : True,\n",
    "    'axes.spines.right' : False,\n",
    "    'axes.spines.top' : False,\n",
    "    'axes.spines.bottom' : True,\n",
    "    'font.family': 'sans',\n",
    "    'font.sans-serif': 'RobotoCondensed-Bold',\n",
    "    'font.serif': 'Lora-Regular',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.grid': True,\n",
    "    'grid.color': 'silver',\n",
    "    'axes.axisbelow': True,\n",
    "    'xtick.bottom' : False,\n",
    "    'ytick.left' : False,\n",
    "    'axes.titlepad' : 15.0,\n",
    "    'legend.frameon' : False,\n",
    "    'ytick.labelsize': 15,\n",
    "    'xtick.labelsize': 15,\n",
    "    'axes.titlesize': 30,\n",
    "    'text.color': '#1B7EBE',\n",
    "    'axes.labelcolor': '#1B7EBE',\n",
    "    'xtick.color': '#1B7EBE',\n",
    "    'ytick.color': '#1B7EBE'\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all-ufo-sightings-thru-08-06-2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.seen_at = pd.to_datetime(df.seen_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD CLOUDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.linspace(0, 50, 100).reshape((10, 10))\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "cmap = plt.get_cmap('bone')\n",
    "new_cmap = truncate_colormap(cmap, 0.0, 0.4)\n",
    "ax[0].imshow(arr, interpolation='nearest', cmap=cmap)\n",
    "ax[1].imshow(arr, interpolation='nearest', cmap=new_cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'the' not in set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decade_wordcloud(df):\n",
    "    beam_mask = np.array(Image.open(\"beam-02.png\"))\n",
    "\n",
    "    description_list = df.text.values.tolist()\n",
    "\n",
    "    word_list = []\n",
    "    \n",
    "    for description in description_list:\n",
    "        tokenized_description = nltk.word_tokenize(description)\n",
    "        for token in tokenized_description:\n",
    "            word_list.append(token)\n",
    "\n",
    "    default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_list = [word.lower() for word in word_list if (len(word) > 2) and (word.isalpha() == True) and (word not in default_stopwords) and (word != 'the') and (word != 'like')]\n",
    "   # word_list = [word for word in word_list if word.isalpha() == True]\n",
    "   # word_list = [word for word in word_list if word not in default_stopwords]\n",
    "   # word_list = [word.lower() for word in word_list]\n",
    "   # word_list = [word for word in word_list if word != '...']\n",
    "\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in word_list]\n",
    "\n",
    "    fdist = nltk.FreqDist(lemma_list)\n",
    "\n",
    "    unigram_wordcloud = WordCloud(colormap=new_cmap, height=300, relative_scaling=.32, width=400, max_words = 80, min_font_size=13, contour_width=2, contour_color='gray', background_color='#8fdeb4', font_path='/Users/kevinlitnav/Library/Fonts/RobotoCondensed-Regular.ttf', mask=beam_mask).generate_from_frequencies(fdist)\n",
    "    \n",
    "    fig, ax = plt.subplots(facecolor='#8fdeb4')\n",
    "\n",
    "    figure(num=None, figsize=(12,8), edgecolor='#8fdeb4')\n",
    "\n",
    "    plt.imshow(unigram_wordcloud, interpolation='bilinear')\n",
    "    plt.grid(False)\n",
    "    plt.xticks(np.arange(0))\n",
    "    plt.yticks(np.arange(0))\n",
    "    plt.tight_layout(pad=0)\n",
    "\n",
    "    plt.savefig('word-cloud-decade.svg', facecolor=fig.get_facecolor(), transparent=True, bbox_inches='tight')\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1970s = df[df.seen_at.dt.year < 1980]\n",
    "df_1980s = df[(df.seen_at.dt.year > 1979) & (df.seen_at.dt.year < 1990)]\n",
    "df_1990s = df[(df.seen_at.dt.year > 1989) & (df.seen_at.dt.year < 2000)]\n",
    "df_2000s = df[(df.seen_at.dt.year > 1999) & (df.seen_at.dt.year < 2010)]\n",
    "df_2010s = df[df.seen_at.dt.year > 2009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_list = df.text.values.tolist()\n",
    "\n",
    "word_list = []\n",
    "    \n",
    "for description in description_list:\n",
    "    tokenized_description = nltk.word_tokenize(description)\n",
    "    for token in tokenized_description:\n",
    "        word_list.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "#word_list = [word for word in word_list if len(word) > 2]\n",
    "#word_list = [word for word in word_list if word.isalpha() == True]\n",
    "word_list = [word for word in word_list if word not in default_stopwords]\n",
    "#word_list = [word.lower() for word in word_list]\n",
    "##word_list = [word for word in word_list if word != '...']\n",
    "#word_list = [word for word in word_list if word != 'the']\n",
    "#word_list = [word for word in word_list if word != 'like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_mask = np.array(Image.open(\"beam-02.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_wordcloud = WordCloud(colormap=new_cmap, height=300, relative_scaling=.32, width=400, max_words = 80, min_font_size=13, contour_width=2, contour_color='gray', background_color='#8fdeb4', font_path='/Users/kevinlitnav/Library/Fonts/RobotoCondensed-Regular.ttf', mask=beam_mask).generate_from_frequencies(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(facecolor='#8fdeb4')\n",
    "\n",
    "figure(num=None, figsize=(12,8), edgecolor='#8fdeb4')\n",
    "\n",
    "plt.imshow(unigram_wordcloud, interpolation='bilinear')\n",
    "plt.grid(False)\n",
    "plt.xticks(np.arange(0))\n",
    "plt.yticks(np.arange(0))\n",
    "plt.tight_layout(pad=0)\n",
    "\n",
    "plt.savefig('word-cloud.svg', facecolor=fig.get_facecolor(), transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFO SHAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shape'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'shape':'craft_shape'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.craft_shape = df.craft_shape.str.replace('Unknown', 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.craft_shape = df.craft_shape.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing_times = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing_times.dropna(subset=['seen_at'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114022, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_missing_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014    8671\n",
       "2012    8092\n",
       "2013    7799\n",
       "2015    6883\n",
       "2016    5624\n",
       "2011    5608\n",
       "2008    5292\n",
       "2017    5255\n",
       "2009    4982\n",
       "2010    4768\n",
       "2004    4737\n",
       "2007    4730\n",
       "2005    4519\n",
       "2003    4413\n",
       "2006    4160\n",
       "2002    3685\n",
       "2001    3530\n",
       "1999    3153\n",
       "2000    3092\n",
       "1998    2020\n",
       "2018    1628\n",
       "1995    1472\n",
       "1997    1438\n",
       "1996    1016\n",
       "1994     505\n",
       "1978     405\n",
       "1993     384\n",
       "1975     383\n",
       "1976     343\n",
       "1977     339\n",
       "1974     326\n",
       "1990     316\n",
       "1992     314\n",
       "1979     306\n",
       "1980     302\n",
       "1989     302\n",
       "1988     288\n",
       "1973     284\n",
       "1991     284\n",
       "1987     278\n",
       "1985     258\n",
       "1986     233\n",
       "1982     224\n",
       "1984     216\n",
       "1972     212\n",
       "1981     210\n",
       "1983     207\n",
       "1970     196\n",
       "1969     190\n",
       "1971     146\n",
       "1968       4\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_missing_times.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing_times['year'] = df_no_missing_times.seen_at.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "crafts_over_years = df_no_missing_times[(df_no_missing_times.craft_shape != 'unknown') & (df_no_missing_times.craft_shape != 'other')].groupby('year').craft_shape.value_counts(normalize=True).unstack()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 27)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crafts_over_years.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crafts_over_years.fillna(0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.meshgrid(crafts_over_years.columns, crafts_over_years.index)\n",
    "\n",
    "crafts_over_years *= 5000\n",
    "plt.scatter(x=x.flatten(), y=y.flatten(), s=crafts_over_years.values.flatten())\n",
    "plt.margins(.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "crafts_over_years = crafts_over_years[['light', 'circle', 'oval', 'sphere', 'triangle', 'fireball', 'disk', 'formation', 'changing', 'cigar']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "crafts_over_years.to_csv('crafts_over_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'shape':'craft_shape'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squarecolors = ['#52bbb7', '#8fdeb4', '#f16764', '#ca4862', '#461d2d', '#1B7EBE', '#E4C34A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_top.tonality_name.value_counts().plot(kind='barh')\n",
    "\n",
    "plt.rcParams.update({'text.color': '#333333',\n",
    "                    'axes.spines.left' : False,\n",
    "                    'axes.spines.bottom' : False})\n",
    "\n",
    "plt.rc('font', size=25)\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='#8fdeb4')\n",
    "\n",
    "shape_labels = [shape.title() for shape in df[(df.craft_shape != 'unknown') & (df.craft_shape != 'other')].craft_shape.value_counts().head(10).index]\n",
    "\n",
    "fig.set_size_inches(14,8)\n",
    "\n",
    "squarecolors = ['#52bbb7', '#f16764', '#ca4862', '#9C2964', '#1B7EBE', '#E4C34A']\n",
    "\n",
    "ax = squarify.plot(sizes=df[(df.craft_shape != 'unknown') & (df.craft_shape != 'other')].craft_shape.value_counts().head(10), label=shape_labels, color=squarecolors, alpha=.8)\n",
    "#plt.axis('off')\n",
    "#plt.show()\n",
    "\n",
    "ax.grid(False)\n",
    "ax.set_xticklabels(labels='')\n",
    "ax.set_yticklabels(labels='')\n",
    "\n",
    "\n",
    "#ax.set_title('UFO shapes', loc='left', pad=10, fontdict={'color': 'dimgray'}, size=30)\n",
    "#ax.text(0,104, 'Of the 100 top rated tabs on Ultimate Guitar, the keys of C and G reign supreme.', fontdict={'color': '#DDDDC9', 'family': 'serif'}, size=20)\n",
    "plt.savefig(\"ufo-shapes.svg\", facecolor=fig.get_facecolor(), transparent=True, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGEXING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains('government')].iloc[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains('Roswell|Area 51|chemtrails|new world order|')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing_times.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing_times[df_no_missing_times.text.str.contains('Delonge')].groupby('year').text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains('abduct')].text[111875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains('NUFORC Note')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains('skeptic')].iloc[120].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains('Close Encounters')].text.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains(r'Independence Day')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains(r'Art Bell')].iloc[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains(r'abduct')].iloc[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.contains('orbs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing_times[(df_no_missing_times.year != 2018) & (df_no_missing_times.text.str.contains(r'abduct'))].groupby('year').text.count().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    blob = TextBlob(s.lower())\n",
    "    words = [token for token in blob.words if token.isalpha() == True and len(token)>3]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', tokenizer=tokenize)\n",
    "\n",
    "matrix = vectorizer.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters = 5\n",
    "km=KMeans(n_clusters=number_of_clusters)\n",
    "km.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sorted_vector(v):\n",
    "    # this \"lambda\" thing is an anonymous function, google me to unluck bonus coding knowledge\n",
    "    sorted_list = sorted(v.items(), key=lambda x: (x[1],x[0]), reverse=True) \n",
    "    sorted_list = sorted_list[:10]\n",
    "    print('\\n'.join([str(x) for x in sorted_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = pd.DataFrame(km.cluster_centers_, columns=vectorizer.get_feature_names())\n",
    "for i in range(number_of_clusters):\n",
    "    print(f'\\nCluster {i}')\n",
    "    print_sorted_vector(centroids.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geotagged = df.dropna(subset=['city_latitude', 'city_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
